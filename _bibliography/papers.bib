---
---

@article{dewaskar2023robustifying,
  title={Robustifying likelihoods by optimistically re-weighting data},
  author={M. Dewaskar and C. Tosh and J. Knoblauch and D. B. Dunson},
  journal={arXiv preprint arXiv:2303.10525},
  arxiv={2303.10525},
  abstract={Likelihood-based inferences have been remarkably successful in wide-spanning application areas. However, even after due diligence in selecting a good model for the data at hand, there is inevitably some amount of model misspecification: outliers, data contamination or inappropriate parametric assumptions such as Gaussianity mean that most models are at best rough approximations of reality. A significant practical concern is that for certain inferences, even small amounts of model misspecification may have a substantial impact; a problem we refer to as brittleness. This article attempts to address the brittleness problem in likelihood-based inferences by choosing the most model friendly data generating process in a discrepancybased neighbourhood of the empirical measure. This leads to a new Optimistically Weighted Likelihood (OWL), which robustifies the original likelihood by formally accounting for a small amount of model misspecification. Focusing on total variation (TV) neighborhoods, we study theoretical properties, develop inference algorithms, and illustrate the methodology in applications to mixture models and regression.},
  pdf={https://arxiv.org/pdf/2303.10525.pdf},
  year={2023}
}

@article{tosh2022targeted,
  title={Targeted active learning for probabilistic models},
  author={C. Tosh and M. Tec and W. Tansey},
  journal={arXiv preprint arXiv:2210.12122},
  arxiv={2210.12122},
  abstract={A fundamental task in science is to design experiments that yield valuable insights about the system under study. Mathematically, these insights can be represented as a utility or risk function that shapes the value of conducting each experiment. We present PDBAL, a targeted active learning method that adaptively designs experiments to maximize scientific utility. PDBAL takes a user-specified risk function and combines it with a probabilistic model of the experimental outcomes to choose designs that rapidly converge on a high-utility model. We prove theoretical bounds on the label complexity of PDBAL and provide fast closed-form solutions for designing experiments with common exponential family likelihoods. In simulation studies, PDBAL consistently outperforms standard untargeted approaches that focus on maximizing expected information gain over the design space. Finally, we demonstrate the scientific potential of PDBAL through a study on a large cancer drug screen dataset where PDBAL quickly recovers the most efficacious drugs with a small fraction of the total number of experiments.},
  pdf={https://arxiv.org/pdf/2210.12122.pdf},
  year={2022}
}

@inproceedings{tosh22simple,
  title = 	 {Simple and near-optimal algorithms for hidden stratification and multi-group learning},
  author =       {C. Tosh and D. Hsu},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {21633--21657},
  year = 	 {2022},
  pdf = 	 {https://proceedings.mlr.press/v162/tosh22a/tosh22a.pdf},
  html = 	 {https://proceedings.mlr.press/v162/tosh22a.html},
  arxiv = {2112.12181},
  errata = {multigroup_err.txt},
  abstract = 	 {Multi-group agnostic learning is a formal learning criterion that is concerned with the conditional risks of predictors within subgroups of a population. The criterion addresses recent practical concerns such as subgroup fairness and hidden stratification. This paper studies the structure of solutions to the multi-group learning problem, and provides simple and near-optimal algorithms for the learning problem.},
  selected={true}
}


@article{tansey22bayesian,
author = {W. Tansey and C. Tosh and D. M. Blei},
title = {{A Bayesian model of dose-response for cancer drug studies}},
volume = {16},
journal = {The Annals of Applied Statistics},
number = {2},
pages = {680 -- 705},
arxiv = {1906.04072},
abstract = {Exploratory cancer drug studies test multiple tumor cell lines against multiple candidate drugs. The goal in each paired (cell line, drug) experiment is to map out the dose-response curve of the cell line as the dose level of the drug increases. We propose Bayesian tensor filtering (BTF), a hierarchical Bayesian model for dose-response modeling in multisample, multitreatment cancer drug studies. BTF uses low-dimensional embeddings to share statistical strength between similar drugs and similar cell lines. Structured shrinkage priors in BTF encourage smoothness in the dose-response curves while remaining adaptive to sharp jumps when the data call for it. We focus on a pair of cancer drug studies exhibiting a particular pathology in their experimental design, leading us to a nonconjugate monotone mixture-of-gammas likelihood. To perform posterior inference, we develop a variant of the elliptical slice sampling algorithm for sampling from linearly-constrained multivariate normal priors with nonconjugate likelihoods. In benchmarks, BTF outperforms state-of-the-art methods for covariance regression and dynamic Poisson matrix factorization. On the two cancer drug studies, BTF outperforms the current standard approach in biology and reveals potential new biomarkers of drug sensitivity in cancer. Code is available at https://github.com/tansey/functionalmf.},
keywords = {constrained inference, Dose-response, matrix factorization, slice sampling, Trend filtering},
pdf = {bayesian_cancer.pdf},
year = {2022}
}


@inproceedings{simchowitz21bayesian,
 author = {M. Simchowitz and C. Tosh and A. Krishnamurthy and D. Hsu and T. Lykouris and M. Dudik and R. Schapire},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Bayesian decision-making under misspecified priors with applications to meta-learning},
 pdf = {https://proceedings.neurips.cc/paper_files/paper/2021/file/ddcbe25988981920c872c1787382f04d-Paper.pdf},
 arxiv = {2107.01509},
 abstract = {Thompson sampling and other Bayesian sequential decision-making algorithms are among the most popular approaches to tackle explore/exploit trade-offs in (contextual) bandits. The choice of prior in these algorithms offers flexibility to encode domain knowledge but can also lead to poor performance when misspecified. In this paper, we demonstrate that performance degrades gracefully with misspecification. We prove that the expected reward accrued by Thompson sampling (TS) with a misspecified prior differs by at most $\tilde{O}(H^2 \epsilon)$ from TS with a well specified prior, where $\epsilon$ is the total-variation distance between priors and H is the learning horizon. Our bound does not require the prior to have any parametric form. For priors with bounded support, our bound is independent of the cardinality or structure of the action space, and we show that it is tight up to universal constants in the worst case.
Building on our sensitivity analysis, we establish generic PAC guarantees for algorithms in the recently studied Bayesian meta-learning setting and derive corollaries for various families of priors. Our results generalize along two axes: (1) they apply to a broader family of Bayesian decision-making algorithms, including a Monte-Carlo implementation of the knowledge gradient algorithm (KG), and (2) they apply to Bayesian POMDPs, the most general Bayesian decision-making setting, encompassing contextual bandits as a special case. Through numerical simulations, we illustrate how prior misspecification and the deployment of one-step look-ahead (as in KG) can impact the convergence of meta-learning in multi-armed and contextual bandits with structured and correlated priors.},
 year = {2021}
}

@article{tosh2021piranha,
  title={The piranha problem: Large effects swimming in a small pond},
  author={C. Tosh and P. Greengard and B. Goodrich and A. Gelman and A. Vehtari and D. Hsu},
  journal={arXiv preprint arXiv:2105.13445},
  arxiv = {2105.13445},
  abstract = {In some scientific fields, it is common to have certain variables of interest that are of particular importance and for which there are many studies indicating a relationship with different explanatory variables. In such cases, particularly those where no relationships are known among the explanatory variables, it is worth asking under what conditions it is possible for all such claimed effects to exist simultaneously. This paper addresses this question by reviewing some theorems from multivariate analysis showing that, unless the explanatory variables also have sizable dependencies with each other, it is impossible to have many such large effects. We discuss implications for the replication crisis in social science.},
  pdf = {https://arxiv.org/pdf/2105.13445.pdf},
  year={2021}
}


@inproceedings{tosh21contrastive,
  title = 	 {Contrastive learning, multi-view redundancy, and linear models},
  author =       {C. Tosh and A. Krishnamurthy and D. Hsu},
  booktitle = 	 {Proceedings of the 32nd International Conference on Algorithmic Learning Theory},
  pages = 	 {1179--1206},
  year = 	 {2021},
  pdf = 	 {http://proceedings.mlr.press/v132/tosh21a/tosh21a.pdf},
  html = 	 {https://proceedings.mlr.press/v132/tosh21a.html},
  arxiv = {2008.10150},
  abstract = 	 {Self-supervised learning is an empirically successful approach to unsupervised learning based on creating artificial supervised learning problems. A popular self-supervised approach to representation learning is contrastive learning, which leverages naturally occurring pairs of similar and dissimilar data points, or multiple views of the same data. This work provides a theoretical analysis of contrastive learning in the multi-view setting, where two views of each datum are available. The main result is that linear functions of the learned representations are nearly optimal on downstream prediction tasks whenever the two views provide redundant information about the label.},
  selected={true}
}


@article{tosh2021contrastivetopic,
  title={Contrastive estimation reveals topic posterior information to linear models},
  author={C. Tosh and A. Krishnamurthy and D. Hsu},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={1},
  pages={12883--12913},
  arxiv = {2003.02234},
  html = {https://jmlr.org/papers/v22/21-0089.html},
  pdf = {https://jmlr.org/papers/volume22/21-0089/21-0089.pdf},
  abstract = {Contrastive learning is an approach to representation learning that utilizes naturally occurring similar and dissimilar pairs of data points to find useful embeddings of data. In the context of document classification under topic modeling assumptions, we prove that contrastive learning is capable of recovering a representation of documents that reveals their underlying topic posterior information to linear models. We apply this procedure in a semi-supervised setup and demonstrate empirically that linear classifiers trained on these representations perform well in document classification tasks with very few training examples.},
  year={2021}
}

@inproceedings{tosh2020diameter,
  title = 	 {Diameter-based interactive structure discovery},
  author =       {C. Tosh and D. Hsu},
  booktitle = 	 {Proceedings of the Twenty-Third International Conference on Artificial Intelligence and Statistics},
  pages = 	 {580--590},
  year = 	 {2020},
  pdf = 	 {http://proceedings.mlr.press/v108/tosh20a/tosh20a.pdf},
  html = 	 {https://proceedings.mlr.press/v108/tosh20a.html},
  arxiv = {1906.02101},
  abstract = 	 {We introduce interactive structure discovery, a generic framework that encompasses many interactive learning settings, including active learning, top-k item identification, interactive drug discovery, and others. We adapt a recently developed active learning algorithm of Tosh and Dasgupta for interactive structure discovery, and show that the new algorithm can be made noise-tolerant and enjoys favorable query complexity bounds.}
}


@article{dasgupta2020expressivity,
  title={Expressivity of expand-and-sparsify representations},
  author={S. Dasgupta and C. Tosh},
  journal={arXiv preprint arXiv:2006.03741},
  arxiv = {2006.03741},
  abstract = {A simple sparse coding mechanism appears in the sensory systems of several organisms: to a coarse approximation, an input $x \in \mathbb{R}^d$ is mapped to much higher dimension $m \gg d$ by a random linear transformation, and is then sparsified by a winner-take-all process in which only the positions of the top $k$ values are retained, yielding a $k$-sparse vector $z \in \{0,1\}^m$. We study the benefits of this representation for subsequent learning.
 
We first show a universal approximation property, that arbitrary continuous functions of $x$ are well approximated by linear functions of $z$, provided $m$ is large enough. This can be interpreted as saying that $z$ unpacks the information in x and makes it more readily accessible. The linear functions can be specified explicitly and are easy to learn, and we give bounds on how large $m$ needs to be as a function of the input dimension $d$ and the smoothness of the target function. Next, we consider whether the representation is adaptive to manifold structure in the input space. This is highly dependent on the specific method of sparsification: we show that adaptivity is not obtained under the winner-take-all mechanism, but does hold under a slight variant. Finally we consider mappings to the representation space that are random but are attuned to the data distribution, and we give favorable approximation bounds in this setting.},
  pdf = {https://arxiv.org/pdf/2006.03741.pdf},
  year={2020}
}


@inproceedings{tosh2019relatve,
  title = {The relative complexity of maximum likelihood estimation, {MAP} estimation, and sampling},
  author =    {C. Tosh and S. Dasgupta},
  booktitle = 	 {Proceedings of the Thirty-Second Conference on Learning Theory},
  pages = 	 {2993--3035},
  year = 	 {2019},
  pdf = 	 {http://proceedings.mlr.press/v99/tosh19a/tosh19a.pdf},
  html = 	 {https://proceedings.mlr.press/v99/tosh19a.html},
  abstract = 	 {We prove that, for a broad range of problems, maximum-a-posteriori (MAP) estimation and approximate sampling of the posterior are at least as computationally difficult as maximum-likelihood (ML) estimation. By way of illustration, we show how hardness results for ML estimation of mixtures of Gaussians and topic models carry over to MAP estimation and approximate sampling under commonly used priors.}
}

@article{dasgupta2019interactive,
  title={Interactive topic modeling with anchor words},
  author={S. Dasgupta and S, Poulis and C. Tosh},
  journal={arXiv preprint arXiv:1907.04919},
  arxiv = {1907.04919},
  abstract = {The formalism of anchor words has enabled the development of fast topic modeling algorithms with provable guarantees. In this paper, we introduce a protocol that allows users to interact with anchor words to build customized and interpretable topic models. Experimental evidence validating the usefulness of our approach is also presented.},
  pdf = {https://arxiv.org/pdf/1907.04919.pdf},
  year={2019}
}

@inproceedings{tosh2018interactive,
 author = {C. Tosh and S. Dasgupta},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Interactive structure learning with structural {Query-by-Committee}},
 pdf = {https://proceedings.neurips.cc/paper_files/paper/2018/file/08c5433a60135c32e34f46a71175850c-Paper.pdf},
 arxiv = {1803.06586},
 abstract = {In this work, we introduce interactive structure learning, a framework that unifies many different interactive learning tasks. We present a generalization of the query-by-committee active learning algorithm for this setting, and we study its consistency and rate of convergence, both theoretically and empirically, with and without noise.},
 html = {https://proceedings.neurips.cc/paper/2018/hash/08c5433a60135c32e34f46a71175850c-Abstract.html},
 year = {2018}
}


@inproceedings{tosh2017diameter,
  title = 	 {Diameter-based active learning},
  author =       {C. Tosh and S. Dasgupta},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {3444--3452},
  year = 	 {2017},
  pdf = 	 {http://proceedings.mlr.press/v70/tosh17a/tosh17a.pdf},
  html = 	 {https://proceedings.mlr.press/v70/tosh17a.html},
  abstract = 	 {To date, the tightest upper and lower-bounds for the active learning of general concept classes have been in terms of a parameter of the learning problem called the splitting index. We provide, for the first time, an efficient algorithm that is able to realize this upper bound, and we empirically demonstrate its good performance.},
  arxiv = {1702.08553},
  selected = {true}
}

@article{tosh2017maximum,
  title={Maximum likelihood estimation for mixtures of spherical {G}aussians is {NP}-hard.},
  author={C. Tosh and S. Dasgupta},
  journal={Journal of Machine Learning Research},
  volume={18},
  pages={175--1},
  pdf = {https://jmlr.org/papers/volume18/16-657/16-657.pdf},
  abstract = {This paper presents NP-hardness and hardness of approximation results for maximum likelihood estimation of mixtures of spherical Gaussians.},
  year={2017}
}


@inproceedings{tosh2016mixing,
  title = 	 {Mixing rates for the alternating {G}ibbs sampler over restricted {B}oltzmann machines and friends},
  author = 	 {C. Tosh},
  booktitle = {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {840--849},
  year = 	 {2016},
  pdf = 	 {http://proceedings.mlr.press/v48/tosh16.pdf},
  html = 	 {https://proceedings.mlr.press/v48/tosh16.html},
  abstract = 	 {Alternating Gibbs sampling is a modification of classical Gibbs sampling where several variables are simultaneously sampled from their joint conditional distribution. In this work, we investigate the mixing rate of alternating Gibbs sampling with a particular emphasis on Restricted Boltzmann Machines (RBMs) and variants.}
}


@inproceedings{tosh2014lower,
  title = 	 {Lower bounds for the {G}ibbs Sampler over mixtures of {G}aussians},
  author = 	 {C. Tosh and S. Dasgupta},
  booktitle = 	 {Proceedings of the 31st International Conference on Machine Learning},
  pages = 	 {1467--1475},
  year = 	 {2014},
  pdf = 	 {http://proceedings.mlr.press/v32/tosh14.pdf},
  html = 	 {https://proceedings.mlr.press/v32/tosh14.html},
  abstract = 	 {The mixing time of a Markov chain is the minimum time t necessary for the total variation distance between the distribution of the Markov chain’s current state X_t and its stationary distribution to fall below some ε&gt; 0. In this paper, we present lower bounds for the mixing time of the Gibbs sampler over Gaussian mixture models with Dirichlet priors.}
}
